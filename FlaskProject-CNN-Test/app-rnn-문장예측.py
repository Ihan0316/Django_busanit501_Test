# import os
# import torch
# import torch.nn as nn
# import torch.optim as optim
# import torch.nn.functional as F
# import torchvision.transforms as transforms
# from flask import Flask, request, jsonify, render_template
# from PIL import Image
# from torch.utils.data import Dataset, DataLoader
#
# # Flask ì•± ìƒì„±
# app = Flask(__name__)
#
# ##############################################################
# import json
# import re
#
# # âœ… JSON íŒŒì¼ ì½ê¸°
# file_path = os.path.join(app.root_path, "íŠ¸ëŸ¼í”„_naver_news.json")
#
# with open(file_path, "r", encoding="utf-8") as file:
#     news_data = json.load(file)  # JSON ë°ì´í„° ë¡œë“œ
# ##############################################################
#
# # âœ… í•œêµ­ì–´ ë¬¸ì¥ ì˜ˆì œ ë°ì´í„°ì…‹
# corpus = [
#     "ë‚˜ëŠ” ë„ˆë¥¼ ì‚¬ë‘í•´",
#     "ë‚˜ëŠ” ì½”ë”©ì„ ì¢‹ì•„í•´",
#     "ë„ˆëŠ” ë‚˜ë¥¼ ì¢‹ì•„í•´",
#     "ë„ˆëŠ” íŒŒì´ì¬ì„ ê³µë¶€í•´",
#     "ìš°ë¦¬ëŠ” ì¸ê³µì§€ëŠ¥ì„ ì—°êµ¬í•´",
#     "ë”¥ëŸ¬ë‹ì€ ì¬ë¯¸ìˆì–´",
#     "íŒŒì´ì¬ì€ ê°•ë ¥í•´",
#     "ë‚˜ëŠ” ìì—°ì–´ì²˜ë¦¬ë¥¼ ê³µë¶€í•´",
# ]
#
#
# ##############################################################
# # âœ… JSON ë°ì´í„°ì—ì„œ 'title' ê°’ë§Œ ì¶”ì¶œí•˜ê³  í•œê¸€ë§Œ ë‚¨ê¸°ê¸°
# def extract_korean(text):
#     """ë¬¸ì¥ì—ì„œ í•œê¸€ë§Œ ë‚¨ê¸°ëŠ” í•¨ìˆ˜"""
#     return re.sub(r"[^ã„±-ã…ê°€-í£ ]+", " ", text)
#
# news_titles = [extract_korean(item["title"]) for item in news_data if "title" in item]
#
# # âœ… corpusì— í•œê¸€ë§Œ ë‚¨ê¸´ ë‰´ìŠ¤ ì œëª© ì¶”ê°€
# corpus.extend(news_titles)
#
# # âœ… ê²°ê³¼ ì¶œë ¥
# print("ğŸ“Œ ìµœì¢… corpus ë¦¬ìŠ¤íŠ¸:")
# print(corpus)
# ##############################################################
#
# # âœ… ë‹¨ì–´ ì‚¬ì „ ë§Œë“¤ê¸°
# word_list = list(set(" ".join(corpus).split()))
# word_dict = {w: i for i, w in enumerate(word_list)}
# idx_dict = {i: w for w, i in word_dict.items()}
#
# # âœ… ìµœëŒ€ ë¬¸ì¥ ê¸¸ì´ ì„¤ì •
# max_len = max(len(s.split()) for s in corpus)
#
# # âœ… ëª¨ë¸ ì •ì˜
# class RNNTextModel(nn.Module):
#     def __init__(self, vocab_size, embed_size, hidden_size, num_classes):
#         super(RNNTextModel, self).__init__()
#         self.embedding = nn.Embedding(vocab_size, embed_size)  # ë‹¨ì–´ ì„ë² ë”©
#         self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)
#         self.fc = nn.Linear(hidden_size, num_classes)
#
#     def forward(self, x):
#         x = self.embedding(x)
#         out, _ = self.rnn(x)
#         out = self.fc(out[:, -1, :])  # ë§ˆì§€ë§‰ ì‹œì ì˜ RNN ì¶œë ¥ì„ ì‚¬ìš©
#         return out
#
#
# # âœ… ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
# def load_model(model_path, vocab_size, embed_size, hidden_size, num_classes):
#     model = RNNTextModel(vocab_size, embed_size, hidden_size, num_classes)
#     model.load_state_dict(torch.load(model_path, map_location=torch.device("cpu")))
#     model.eval()
#     return model
#
#
# # âœ… ëª¨ë¸ ë¡œë“œ
# # model_path = "model/rnn_korean_model.pth"
# model_path = "model/rnn_news_model.pth"
#
# model = load_model(model_path, len(word_dict), 10, 16, len(word_dict))
#
#
# # âœ… ë¬¸ì¥ ì˜ˆì¸¡ í•¨ìˆ˜
# def predict_next_word(sentence):
#     if model is None:
#         return "", 0.0
#
#     model.eval()  # âœ… í‰ê°€ ëª¨ë“œ ì„¤ì •
#     words = sentence.strip().split()  # âœ… ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
#     input_seq = [word_dict[w] for w in words if w in word_dict]
#
#     # âœ… íŒ¨ë”© ì¶”ê°€ (ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´)
#     input_padded = input_seq + [0] * (max_len - len(input_seq))
#     device = next(model.parameters()).device  # âœ… ëª¨ë¸ì´ ìœ„ì¹˜í•œ ì¥ì¹˜ í™•ì¸
#     input_tensor = torch.tensor([input_padded], dtype=torch.long).to(device)
#
#     # âœ… ëª¨ë¸ ì˜ˆì¸¡
#     with torch.no_grad():
#         output = model(input_tensor)
#         probabilities = F.softmax(output[0], dim=0)
#         predicted_idx = torch.argmax(probabilities).item()
#         confidence = probabilities[predicted_idx].item()
#
#     predicted_word = idx_dict[predicted_idx]
#     return predicted_word, confidence
#
#
# # âœ… ì›¹í˜ì´ì§€ ë Œë”ë§
# @app.route("/")
# def index():
#     return render_template("index.html")
#
#
# # âœ… ì˜ˆì¸¡ API
# @app.route("/predict", methods=["POST"])
# def predict():
#     data = request.get_json()
#     sentence = data.get("sentence", "")
#     if not sentence:
#         return jsonify({"error": "No sentence provided"}), 400
#
#     predicted_word, confidence = predict_next_word(sentence)
#     return jsonify({"predicted_word": predicted_word, "confidence": round(confidence * 100, 2)})
#
#
# # âœ… Flask ì„œë²„ ì‹¤í–‰
# if __name__ == "__main__":
#     app.run(debug=True)
#
